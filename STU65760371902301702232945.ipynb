{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e8d3dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 rows and 11 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "# Womens Clothing E-Commerce Reviews.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
    "df = pd.read_csv(r'C:\\Users\\sheet\\Downloads\\Womens Clothing E-Commerce Reviews\\Womens Clothing E-Commerce Reviews.csv', delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = 'Womens Clothing E-Commerce Reviews.csv'\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bda65c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clothing ID  Age                    Title  \\\n",
       "0          767   33                      NaN   \n",
       "1         1080   34                      NaN   \n",
       "2         1077   60  Some major design flaws   \n",
       "3         1049   50         My favorite buy!   \n",
       "4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a3a2a6",
   "metadata": {},
   "source": [
    "# Handling Missing Values: \n",
    "Check for missing values Decide whether to drop or fill missing values based on the dataset size and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46762f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                  0\n",
       "Age                          0\n",
       "Title                      190\n",
       "Review Text                 42\n",
       "Rating                       0\n",
       "Recommended IND              0\n",
       "Positive Feedback Count      0\n",
       "Division Name                0\n",
       "Department Name              0\n",
       "Class Name                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66967062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                 0\n",
       "Age                         0\n",
       "Title                      42\n",
       "Review Text                42\n",
       "Rating                      0\n",
       "Recommended IND             0\n",
       "Positive Feedback Count     0\n",
       "Division Name               0\n",
       "Department Name             0\n",
       "Class Name                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filled the missing title with review text\n",
    "df['Title'].fillna(df['Review Text'], inplace=True)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10c48dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clothing ID                0\n",
       "Age                        0\n",
       "Title                      0\n",
       "Review Text                0\n",
       "Rating                     0\n",
       "Recommended IND            0\n",
       "Positive Feedback Count    0\n",
       "Division Name              0\n",
       "Department Name            0\n",
       "Class Name                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#further dropping the 42 rows, as it comprises only 4% of the total data\n",
    "df = df.dropna(subset=['Review Text'])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5330288",
   "metadata": {},
   "source": [
    "## Text Cleaning:\n",
    "\n",
    "1) **Lowercasing**: Convert all text to lowercase to ensure uniformity.\n",
    "\n",
    "2) **Special Characters and Numbers**: Remove any special characters, numbers, and symbols from the text.\n",
    "\n",
    "3) **Tokenization**: Break down the text into individual words or tokens.\n",
    "\n",
    "4) **Stop Words**: Remove common stop words (e.g., 'the', 'and', 'is') as they usually don't contribute much to sentiment.\n",
    "\n",
    "5) *Lemmatization*: Reduce words to their base or root form. This helps in consolidating words with similar meanings.\n",
    "\n",
    "Depending on your analysis goals, you might choose to drop columns that are not relevant for sentiment analysis. Check for the difference between lemmetization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0cc769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>love dress sooo pretty happened find store im ...</td>\n",
       "      <td>love dress sooo pretty happened find store im ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>high hope dress really wanted work initially o...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>favorite buy</td>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>flattering shirt</td>\n",
       "      <td>shirt flattering due adjustable front tie perf...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1047</td>\n",
       "      <td>70</td>\n",
       "      <td>received christmas gift daughter wonderful war...</td>\n",
       "      <td>received christmas gift daughter wonderful war...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>936</td>\n",
       "      <td>37</td>\n",
       "      <td>gorgeous</td>\n",
       "      <td>every year around time beloved retailer come w...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>936</td>\n",
       "      <td>36</td>\n",
       "      <td>gorgeous</td>\n",
       "      <td>tried sweater store immediately ordered size g...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>854</td>\n",
       "      <td>29</td>\n",
       "      <td>soft</td>\n",
       "      <td>super soft comfortable run little large cozy</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>936</td>\n",
       "      <td>34</td>\n",
       "      <td>love lightweight coat</td>\n",
       "      <td>wear collar favor grace kelly pull oversized h...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clothing ID  Age                                              Title  \\\n",
       "0            767   33        absolutely wonderful silky sexy comfortable   \n",
       "1           1080   34  love dress sooo pretty happened find store im ...   \n",
       "2           1077   60                                  major design flaw   \n",
       "3           1049   50                                       favorite buy   \n",
       "4            847   47                                   flattering shirt   \n",
       "..           ...  ...                                                ...   \n",
       "995         1047   70  received christmas gift daughter wonderful war...   \n",
       "996          936   37                                           gorgeous   \n",
       "997          936   36                                           gorgeous   \n",
       "998          854   29                                               soft   \n",
       "999          936   34                              love lightweight coat   \n",
       "\n",
       "                                           Review Text  Rating  \\\n",
       "0          absolutely wonderful silky sexy comfortable       4   \n",
       "1    love dress sooo pretty happened find store im ...       5   \n",
       "2    high hope dress really wanted work initially o...       3   \n",
       "3    love love love jumpsuit fun flirty fabulous ev...       5   \n",
       "4    shirt flattering due adjustable front tie perf...       5   \n",
       "..                                                 ...     ...   \n",
       "995  received christmas gift daughter wonderful war...       5   \n",
       "996  every year around time beloved retailer come w...       5   \n",
       "997  tried sweater store immediately ordered size g...       5   \n",
       "998       super soft comfortable run little large cozy       5   \n",
       "999  wear collar favor grace kelly pull oversized h...       5   \n",
       "\n",
       "     Recommended IND  Positive Feedback Count   Division Name Department Name  \\\n",
       "0                  1                        0       Initmates        Intimate   \n",
       "1                  1                        4         General         Dresses   \n",
       "2                  0                        0         General         Dresses   \n",
       "3                  1                        0  General Petite         Bottoms   \n",
       "4                  1                        6         General            Tops   \n",
       "..               ...                      ...             ...             ...   \n",
       "995                1                        3         General         Bottoms   \n",
       "996                1                        8         General            Tops   \n",
       "997                1                        1         General            Tops   \n",
       "998                1                        0  General Petite            Tops   \n",
       "999                1                        2         General            Tops   \n",
       "\n",
       "    Class Name  \n",
       "0    Intimates  \n",
       "1      Dresses  \n",
       "2      Dresses  \n",
       "3        Pants  \n",
       "4      Blouses  \n",
       "..         ...  \n",
       "995      Pants  \n",
       "996   Sweaters  \n",
       "997   Sweaters  \n",
       "998      Knits  \n",
       "999   Sweaters  \n",
       "\n",
       "[958 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Check for NaN values\n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing special characters and numbers\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Removing stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to 'Review Text'\n",
    "df['Review Text'] = df['Review Text'].apply(preprocess_text)\n",
    "\n",
    "# Apply preprocessing to 'Title'\n",
    "df['Title'] = df['Title'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd31bedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>958.000000</td>\n",
       "      <td>958.000000</td>\n",
       "      <td>958.000000</td>\n",
       "      <td>958.000000</td>\n",
       "      <td>958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>909.411273</td>\n",
       "      <td>43.653445</td>\n",
       "      <td>4.179541</td>\n",
       "      <td>0.814196</td>\n",
       "      <td>2.728601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>199.349768</td>\n",
       "      <td>12.422842</td>\n",
       "      <td>1.082355</td>\n",
       "      <td>0.389151</td>\n",
       "      <td>5.796933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>907.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1060.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1196.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID         Age      Rating  Recommended IND  \\\n",
       "count   958.000000  958.000000  958.000000       958.000000   \n",
       "mean    909.411273   43.653445    4.179541         0.814196   \n",
       "std     199.349768   12.422842    1.082355         0.389151   \n",
       "min       2.000000   20.000000    1.000000         0.000000   \n",
       "25%     850.000000   35.000000    4.000000         1.000000   \n",
       "50%     907.000000   41.000000    5.000000         1.000000   \n",
       "75%    1060.000000   52.000000    5.000000         1.000000   \n",
       "max    1196.000000   93.000000    5.000000         1.000000   \n",
       "\n",
       "       Positive Feedback Count  \n",
       "count               958.000000  \n",
       "mean                  2.728601  \n",
       "std                   5.796933  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   3.000000  \n",
       "max                  84.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec2678",
   "metadata": {},
   "source": [
    "We see that there are no outliers in the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e803c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>absolutely wonderful silky sexy comfortable</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>love dress sooo pretty happened find store im ...</td>\n",
       "      <td>love dress sooo pretty happened find store im ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>major design flaw</td>\n",
       "      <td>high hope dress really wanted work initially o...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>favorite buy</td>\n",
       "      <td>love love love jumpsuit fun flirty fabulous ev...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>flattering shirt</td>\n",
       "      <td>shirt flattering due adjustable front tie perf...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1047</td>\n",
       "      <td>70</td>\n",
       "      <td>received christmas gift daughter wonderful war...</td>\n",
       "      <td>received christmas gift daughter wonderful war...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>936</td>\n",
       "      <td>37</td>\n",
       "      <td>gorgeous</td>\n",
       "      <td>every year around time beloved retailer come w...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>936</td>\n",
       "      <td>36</td>\n",
       "      <td>gorgeous</td>\n",
       "      <td>tried sweater store immediately ordered size g...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>854</td>\n",
       "      <td>29</td>\n",
       "      <td>soft</td>\n",
       "      <td>super soft comfortable run little large cozy</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>936</td>\n",
       "      <td>34</td>\n",
       "      <td>love lightweight coat</td>\n",
       "      <td>wear collar favor grace kelly pull oversized h...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Clothing ID  Age                                              Title  \\\n",
       "0            767   33        absolutely wonderful silky sexy comfortable   \n",
       "1           1080   34  love dress sooo pretty happened find store im ...   \n",
       "2           1077   60                                  major design flaw   \n",
       "3           1049   50                                       favorite buy   \n",
       "4            847   47                                   flattering shirt   \n",
       "..           ...  ...                                                ...   \n",
       "995         1047   70  received christmas gift daughter wonderful war...   \n",
       "996          936   37                                           gorgeous   \n",
       "997          936   36                                           gorgeous   \n",
       "998          854   29                                               soft   \n",
       "999          936   34                              love lightweight coat   \n",
       "\n",
       "                                           Review Text  Rating  \\\n",
       "0          absolutely wonderful silky sexy comfortable       4   \n",
       "1    love dress sooo pretty happened find store im ...       5   \n",
       "2    high hope dress really wanted work initially o...       3   \n",
       "3    love love love jumpsuit fun flirty fabulous ev...       5   \n",
       "4    shirt flattering due adjustable front tie perf...       5   \n",
       "..                                                 ...     ...   \n",
       "995  received christmas gift daughter wonderful war...       5   \n",
       "996  every year around time beloved retailer come w...       5   \n",
       "997  tried sweater store immediately ordered size g...       5   \n",
       "998       super soft comfortable run little large cozy       5   \n",
       "999  wear collar favor grace kelly pull oversized h...       5   \n",
       "\n",
       "     Recommended IND  Positive Feedback Count   Division Name Department Name  \\\n",
       "0                  1                        0       Initmates        Intimate   \n",
       "1                  1                        4         General         Dresses   \n",
       "2                  0                        0         General         Dresses   \n",
       "3                  1                        0  General Petite         Bottoms   \n",
       "4                  1                        6         General            Tops   \n",
       "..               ...                      ...             ...             ...   \n",
       "995                1                        3         General         Bottoms   \n",
       "996                1                        8         General            Tops   \n",
       "997                1                        1         General            Tops   \n",
       "998                1                        0  General Petite            Tops   \n",
       "999                1                        2         General            Tops   \n",
       "\n",
       "    Class Name Sentiment  \n",
       "0    Intimates  positive  \n",
       "1      Dresses  positive  \n",
       "2      Dresses   neutral  \n",
       "3        Pants  positive  \n",
       "4      Blouses  positive  \n",
       "..         ...       ...  \n",
       "995      Pants  positive  \n",
       "996   Sweaters  positive  \n",
       "997   Sweaters  positive  \n",
       "998      Knits  positive  \n",
       "999   Sweaters  positive  \n",
       "\n",
       "[958 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorize ratings as positive, negative, or neutral\n",
    "def categorize_rating(rating):\n",
    "    if rating >= 4:\n",
    "        return 'positive'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply the categorization to create a new 'Sentiment' column\n",
    "df['Sentiment'] = df['Rating'].apply(categorize_rating)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62b23746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines (SVM) Results:\n",
      "Accuracy: 0.7881944444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.17      0.03      0.04        39\n",
      "    positive       0.80      0.99      0.88       220\n",
      "\n",
      "    accuracy                           0.79       288\n",
      "   macro avg       0.62      0.44      0.46       288\n",
      "weighted avg       0.72      0.79      0.73       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Review Text'], df['Sentiment'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=650)  # You can adjust max_features based on your dataset size\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "svm_predictions = svm_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Support Vector Machines (SVM) Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67fded2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines (SVM) Results:\n",
      "Accuracy: 0.8611111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.69      0.62        29\n",
      "     neutral       0.50      0.23      0.32        39\n",
      "    positive       0.93      1.00      0.96       220\n",
      "\n",
      "    accuracy                           0.86       288\n",
      "   macro avg       0.67      0.64      0.63       288\n",
      "weighted avg       0.84      0.86      0.84       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "# Selecting features\n",
    "selected_features = ['Age', 'Review Text', 'Rating','Title', 'Positive Feedback Count','Recommended IND', 'Division Name', 'Department Name', 'Class Name']\n",
    "X = df[selected_features]\n",
    "y = df['Sentiment']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer_text = TfidfVectorizer(max_features=650)\n",
    "X_train_text_vectorized = vectorizer_text.fit_transform(X_train['Review Text'])\n",
    "X_test_text_vectorized = vectorizer_text.transform(X_test['Review Text'])\n",
    "\n",
    "# Vectorize title data\n",
    "vectorizer_title = TfidfVectorizer(max_features=200)  # You can adjust max_features based on your dataset size\n",
    "X_train_title_vectorized = vectorizer_title.fit_transform(X_train['Title'])\n",
    "X_test_title_vectorized = vectorizer_title.transform(X_test['Title'])\n",
    "\n",
    "# Combine text features with other selected features\n",
    "X_train_vectorized = hstack([X_train_text_vectorized, X_train_title_vectorized, X_train[['Recommended IND','Positive Feedback Count']]])\n",
    "X_test_vectorized = hstack([X_test_text_vectorized, X_test_title_vectorized, X_test[['Recommended IND','Positive Feedback Count']]])\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "svm_predictions = svm_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Support Vector Machines (SVM) Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(classification_report(y_test, svm_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4ba29451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.9712611\ttotal: 21.2ms\tremaining: 8.44s\n",
      "1:\tlearn: 0.8747219\ttotal: 38.7ms\tremaining: 7.7s\n",
      "2:\tlearn: 0.7972876\ttotal: 54.5ms\tremaining: 7.21s\n",
      "3:\tlearn: 0.7344461\ttotal: 70.7ms\tremaining: 7s\n",
      "4:\tlearn: 0.6804152\ttotal: 86.3ms\tremaining: 6.82s\n",
      "5:\tlearn: 0.6342612\ttotal: 102ms\tremaining: 6.69s\n",
      "6:\tlearn: 0.5964269\ttotal: 117ms\tremaining: 6.59s\n",
      "7:\tlearn: 0.5630736\ttotal: 133ms\tremaining: 6.53s\n",
      "8:\tlearn: 0.5354551\ttotal: 149ms\tremaining: 6.46s\n",
      "9:\tlearn: 0.5114977\ttotal: 164ms\tremaining: 6.39s\n",
      "10:\tlearn: 0.4902582\ttotal: 179ms\tremaining: 6.34s\n",
      "11:\tlearn: 0.4710860\ttotal: 195ms\tremaining: 6.3s\n",
      "12:\tlearn: 0.4603218\ttotal: 211ms\tremaining: 6.27s\n",
      "13:\tlearn: 0.4452511\ttotal: 227ms\tremaining: 6.26s\n",
      "14:\tlearn: 0.4378049\ttotal: 242ms\tremaining: 6.22s\n",
      "15:\tlearn: 0.4261011\ttotal: 258ms\tremaining: 6.19s\n",
      "16:\tlearn: 0.4137371\ttotal: 273ms\tremaining: 6.16s\n",
      "17:\tlearn: 0.4087807\ttotal: 289ms\tremaining: 6.13s\n",
      "18:\tlearn: 0.3985743\ttotal: 303ms\tremaining: 6.08s\n",
      "19:\tlearn: 0.3911176\ttotal: 318ms\tremaining: 6.05s\n",
      "20:\tlearn: 0.3881823\ttotal: 334ms\tremaining: 6.03s\n",
      "21:\tlearn: 0.3845099\ttotal: 350ms\tremaining: 6.01s\n",
      "22:\tlearn: 0.3779226\ttotal: 365ms\tremaining: 5.99s\n",
      "23:\tlearn: 0.3719392\ttotal: 380ms\tremaining: 5.96s\n",
      "24:\tlearn: 0.3688416\ttotal: 396ms\tremaining: 5.94s\n",
      "25:\tlearn: 0.3658237\ttotal: 411ms\tremaining: 5.91s\n",
      "26:\tlearn: 0.3601391\ttotal: 428ms\tremaining: 5.92s\n",
      "27:\tlearn: 0.3580567\ttotal: 444ms\tremaining: 5.89s\n",
      "28:\tlearn: 0.3559418\ttotal: 459ms\tremaining: 5.88s\n",
      "29:\tlearn: 0.3535853\ttotal: 476ms\tremaining: 5.87s\n",
      "30:\tlearn: 0.3490833\ttotal: 494ms\tremaining: 5.88s\n",
      "31:\tlearn: 0.3476717\ttotal: 509ms\tremaining: 5.85s\n",
      "32:\tlearn: 0.3434758\ttotal: 524ms\tremaining: 5.82s\n",
      "33:\tlearn: 0.3423601\ttotal: 538ms\tremaining: 5.79s\n",
      "34:\tlearn: 0.3385884\ttotal: 552ms\tremaining: 5.76s\n",
      "35:\tlearn: 0.3371427\ttotal: 567ms\tremaining: 5.73s\n",
      "36:\tlearn: 0.3360219\ttotal: 581ms\tremaining: 5.7s\n",
      "37:\tlearn: 0.3346188\ttotal: 596ms\tremaining: 5.68s\n",
      "38:\tlearn: 0.3334768\ttotal: 612ms\tremaining: 5.67s\n",
      "39:\tlearn: 0.3325775\ttotal: 627ms\tremaining: 5.64s\n",
      "40:\tlearn: 0.3316767\ttotal: 641ms\tremaining: 5.61s\n",
      "41:\tlearn: 0.3295718\ttotal: 655ms\tremaining: 5.59s\n",
      "42:\tlearn: 0.3263090\ttotal: 671ms\tremaining: 5.57s\n",
      "43:\tlearn: 0.3251671\ttotal: 685ms\tremaining: 5.54s\n",
      "44:\tlearn: 0.3237856\ttotal: 699ms\tremaining: 5.51s\n",
      "45:\tlearn: 0.3226217\ttotal: 714ms\tremaining: 5.49s\n",
      "46:\tlearn: 0.3211199\ttotal: 728ms\tremaining: 5.47s\n",
      "47:\tlearn: 0.3206905\ttotal: 743ms\tremaining: 5.45s\n",
      "48:\tlearn: 0.3193004\ttotal: 758ms\tremaining: 5.43s\n",
      "49:\tlearn: 0.3187882\ttotal: 773ms\tremaining: 5.41s\n",
      "50:\tlearn: 0.3173219\ttotal: 788ms\tremaining: 5.39s\n",
      "51:\tlearn: 0.3144975\ttotal: 802ms\tremaining: 5.37s\n",
      "52:\tlearn: 0.3127457\ttotal: 818ms\tremaining: 5.35s\n",
      "53:\tlearn: 0.3121051\ttotal: 832ms\tremaining: 5.33s\n",
      "54:\tlearn: 0.3105858\ttotal: 848ms\tremaining: 5.32s\n",
      "55:\tlearn: 0.3089534\ttotal: 862ms\tremaining: 5.29s\n",
      "56:\tlearn: 0.3076505\ttotal: 876ms\tremaining: 5.27s\n",
      "57:\tlearn: 0.3071352\ttotal: 890ms\tremaining: 5.25s\n",
      "58:\tlearn: 0.3063173\ttotal: 904ms\tremaining: 5.23s\n",
      "59:\tlearn: 0.3054663\ttotal: 919ms\tremaining: 5.21s\n",
      "60:\tlearn: 0.3048307\ttotal: 934ms\tremaining: 5.19s\n",
      "61:\tlearn: 0.3019742\ttotal: 949ms\tremaining: 5.17s\n",
      "62:\tlearn: 0.3007160\ttotal: 964ms\tremaining: 5.16s\n",
      "63:\tlearn: 0.2998802\ttotal: 979ms\tremaining: 5.14s\n",
      "64:\tlearn: 0.2986851\ttotal: 994ms\tremaining: 5.12s\n",
      "65:\tlearn: 0.2961347\ttotal: 1.01s\tremaining: 5.12s\n",
      "66:\tlearn: 0.2951973\ttotal: 1.03s\tremaining: 5.1s\n",
      "67:\tlearn: 0.2929050\ttotal: 1.04s\tremaining: 5.09s\n",
      "68:\tlearn: 0.2908179\ttotal: 1.05s\tremaining: 5.07s\n",
      "69:\tlearn: 0.2900662\ttotal: 1.07s\tremaining: 5.05s\n",
      "70:\tlearn: 0.2883771\ttotal: 1.09s\tremaining: 5.03s\n",
      "71:\tlearn: 0.2869350\ttotal: 1.1s\tremaining: 5.03s\n",
      "72:\tlearn: 0.2853595\ttotal: 1.12s\tremaining: 5s\n",
      "73:\tlearn: 0.2842559\ttotal: 1.13s\tremaining: 4.99s\n",
      "74:\tlearn: 0.2829734\ttotal: 1.15s\tremaining: 4.97s\n",
      "75:\tlearn: 0.2823143\ttotal: 1.16s\tremaining: 4.96s\n",
      "76:\tlearn: 0.2799037\ttotal: 1.18s\tremaining: 4.94s\n",
      "77:\tlearn: 0.2792398\ttotal: 1.19s\tremaining: 4.92s\n",
      "78:\tlearn: 0.2771800\ttotal: 1.21s\tremaining: 4.91s\n",
      "79:\tlearn: 0.2766752\ttotal: 1.22s\tremaining: 4.89s\n",
      "80:\tlearn: 0.2756104\ttotal: 1.24s\tremaining: 4.88s\n",
      "81:\tlearn: 0.2733042\ttotal: 1.25s\tremaining: 4.87s\n",
      "82:\tlearn: 0.2719900\ttotal: 1.27s\tremaining: 4.85s\n",
      "83:\tlearn: 0.2713025\ttotal: 1.28s\tremaining: 4.83s\n",
      "84:\tlearn: 0.2696879\ttotal: 1.3s\tremaining: 4.82s\n",
      "85:\tlearn: 0.2689313\ttotal: 1.31s\tremaining: 4.8s\n",
      "86:\tlearn: 0.2674100\ttotal: 1.33s\tremaining: 4.79s\n",
      "87:\tlearn: 0.2666164\ttotal: 1.34s\tremaining: 4.77s\n",
      "88:\tlearn: 0.2659985\ttotal: 1.36s\tremaining: 4.75s\n",
      "89:\tlearn: 0.2654158\ttotal: 1.37s\tremaining: 4.73s\n",
      "90:\tlearn: 0.2645374\ttotal: 1.39s\tremaining: 4.72s\n",
      "91:\tlearn: 0.2641701\ttotal: 1.4s\tremaining: 4.7s\n",
      "92:\tlearn: 0.2630602\ttotal: 1.42s\tremaining: 4.69s\n",
      "93:\tlearn: 0.2626228\ttotal: 1.44s\tremaining: 4.67s\n",
      "94:\tlearn: 0.2609263\ttotal: 1.45s\tremaining: 4.66s\n",
      "95:\tlearn: 0.2603385\ttotal: 1.46s\tremaining: 4.64s\n",
      "96:\tlearn: 0.2596985\ttotal: 1.48s\tremaining: 4.62s\n",
      "97:\tlearn: 0.2585193\ttotal: 1.49s\tremaining: 4.61s\n",
      "98:\tlearn: 0.2579871\ttotal: 1.51s\tremaining: 4.59s\n",
      "99:\tlearn: 0.2570975\ttotal: 1.53s\tremaining: 4.58s\n",
      "100:\tlearn: 0.2565632\ttotal: 1.54s\tremaining: 4.57s\n",
      "101:\tlearn: 0.2556786\ttotal: 1.56s\tremaining: 4.55s\n",
      "102:\tlearn: 0.2550428\ttotal: 1.57s\tremaining: 4.54s\n",
      "103:\tlearn: 0.2538297\ttotal: 1.59s\tremaining: 4.53s\n",
      "104:\tlearn: 0.2530888\ttotal: 1.6s\tremaining: 4.51s\n",
      "105:\tlearn: 0.2526187\ttotal: 1.62s\tremaining: 4.5s\n",
      "106:\tlearn: 0.2519327\ttotal: 1.64s\tremaining: 4.49s\n",
      "107:\tlearn: 0.2510771\ttotal: 1.65s\tremaining: 4.47s\n",
      "108:\tlearn: 0.2505234\ttotal: 1.67s\tremaining: 4.46s\n",
      "109:\tlearn: 0.2501396\ttotal: 1.68s\tremaining: 4.44s\n",
      "110:\tlearn: 0.2497552\ttotal: 1.7s\tremaining: 4.42s\n",
      "111:\tlearn: 0.2489048\ttotal: 1.72s\tremaining: 4.41s\n",
      "112:\tlearn: 0.2477816\ttotal: 1.73s\tremaining: 4.39s\n",
      "113:\tlearn: 0.2469796\ttotal: 1.75s\tremaining: 4.38s\n",
      "114:\tlearn: 0.2454680\ttotal: 1.76s\tremaining: 4.37s\n",
      "115:\tlearn: 0.2448097\ttotal: 1.78s\tremaining: 4.35s\n",
      "116:\tlearn: 0.2431352\ttotal: 1.79s\tremaining: 4.33s\n",
      "117:\tlearn: 0.2419531\ttotal: 1.81s\tremaining: 4.32s\n",
      "118:\tlearn: 0.2411765\ttotal: 1.82s\tremaining: 4.31s\n",
      "119:\tlearn: 0.2407663\ttotal: 1.84s\tremaining: 4.29s\n",
      "120:\tlearn: 0.2401219\ttotal: 1.85s\tremaining: 4.28s\n",
      "121:\tlearn: 0.2389185\ttotal: 1.87s\tremaining: 4.27s\n",
      "122:\tlearn: 0.2378621\ttotal: 1.89s\tremaining: 4.25s\n",
      "123:\tlearn: 0.2373593\ttotal: 1.91s\tremaining: 4.25s\n",
      "124:\tlearn: 0.2352266\ttotal: 1.92s\tremaining: 4.23s\n",
      "125:\tlearn: 0.2346479\ttotal: 1.94s\tremaining: 4.22s\n",
      "126:\tlearn: 0.2340201\ttotal: 1.95s\tremaining: 4.2s\n",
      "127:\tlearn: 0.2334994\ttotal: 1.97s\tremaining: 4.19s\n",
      "128:\tlearn: 0.2326111\ttotal: 1.99s\tremaining: 4.17s\n",
      "129:\tlearn: 0.2320338\ttotal: 2s\tremaining: 4.15s\n",
      "130:\tlearn: 0.2313266\ttotal: 2.02s\tremaining: 4.14s\n",
      "131:\tlearn: 0.2309235\ttotal: 2.03s\tremaining: 4.13s\n",
      "132:\tlearn: 0.2303450\ttotal: 2.05s\tremaining: 4.11s\n",
      "133:\tlearn: 0.2300100\ttotal: 2.06s\tremaining: 4.1s\n",
      "134:\tlearn: 0.2294918\ttotal: 2.08s\tremaining: 4.08s\n",
      "135:\tlearn: 0.2290461\ttotal: 2.1s\tremaining: 4.07s\n",
      "136:\tlearn: 0.2285243\ttotal: 2.11s\tremaining: 4.05s\n",
      "137:\tlearn: 0.2281134\ttotal: 2.12s\tremaining: 4.03s\n",
      "138:\tlearn: 0.2261832\ttotal: 2.14s\tremaining: 4.02s\n",
      "139:\tlearn: 0.2252098\ttotal: 2.15s\tremaining: 4s\n",
      "140:\tlearn: 0.2247145\ttotal: 2.17s\tremaining: 3.99s\n",
      "141:\tlearn: 0.2239978\ttotal: 2.19s\tremaining: 3.97s\n",
      "142:\tlearn: 0.2235801\ttotal: 2.2s\tremaining: 3.95s\n",
      "143:\tlearn: 0.2229399\ttotal: 2.21s\tremaining: 3.94s\n",
      "144:\tlearn: 0.2224120\ttotal: 2.23s\tremaining: 3.92s\n",
      "145:\tlearn: 0.2218252\ttotal: 2.24s\tremaining: 3.9s\n",
      "146:\tlearn: 0.2211487\ttotal: 2.26s\tremaining: 3.89s\n",
      "147:\tlearn: 0.2207519\ttotal: 2.27s\tremaining: 3.87s\n",
      "148:\tlearn: 0.2202869\ttotal: 2.29s\tremaining: 3.86s\n",
      "149:\tlearn: 0.2199333\ttotal: 2.3s\tremaining: 3.84s\n",
      "150:\tlearn: 0.2192459\ttotal: 2.32s\tremaining: 3.82s\n",
      "151:\tlearn: 0.2184705\ttotal: 2.33s\tremaining: 3.81s\n",
      "152:\tlearn: 0.2168547\ttotal: 2.35s\tremaining: 3.79s\n",
      "153:\tlearn: 0.2157575\ttotal: 2.36s\tremaining: 3.77s\n",
      "154:\tlearn: 0.2151681\ttotal: 2.38s\tremaining: 3.76s\n",
      "155:\tlearn: 0.2145301\ttotal: 2.39s\tremaining: 3.74s\n",
      "156:\tlearn: 0.2141974\ttotal: 2.41s\tremaining: 3.73s\n",
      "157:\tlearn: 0.2136639\ttotal: 2.42s\tremaining: 3.71s\n",
      "158:\tlearn: 0.2133299\ttotal: 2.44s\tremaining: 3.69s\n",
      "159:\tlearn: 0.2130222\ttotal: 2.45s\tremaining: 3.68s\n",
      "160:\tlearn: 0.2125860\ttotal: 2.47s\tremaining: 3.66s\n",
      "161:\tlearn: 0.2121195\ttotal: 2.48s\tremaining: 3.65s\n",
      "162:\tlearn: 0.2117874\ttotal: 2.5s\tremaining: 3.63s\n",
      "163:\tlearn: 0.2111168\ttotal: 2.51s\tremaining: 3.62s\n",
      "164:\tlearn: 0.2103570\ttotal: 2.53s\tremaining: 3.61s\n",
      "165:\tlearn: 0.2097402\ttotal: 2.55s\tremaining: 3.59s\n",
      "166:\tlearn: 0.2088481\ttotal: 2.56s\tremaining: 3.57s\n",
      "167:\tlearn: 0.2082804\ttotal: 2.58s\tremaining: 3.56s\n",
      "168:\tlearn: 0.2078726\ttotal: 2.59s\tremaining: 3.54s\n",
      "169:\tlearn: 0.2071031\ttotal: 2.61s\tremaining: 3.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170:\tlearn: 0.2063347\ttotal: 2.62s\tremaining: 3.51s\n",
      "171:\tlearn: 0.2051407\ttotal: 2.64s\tremaining: 3.5s\n",
      "172:\tlearn: 0.2045984\ttotal: 2.65s\tremaining: 3.48s\n",
      "173:\tlearn: 0.2040380\ttotal: 2.67s\tremaining: 3.47s\n",
      "174:\tlearn: 0.2034715\ttotal: 2.68s\tremaining: 3.45s\n",
      "175:\tlearn: 0.2031690\ttotal: 2.7s\tremaining: 3.43s\n",
      "176:\tlearn: 0.2027309\ttotal: 2.71s\tremaining: 3.42s\n",
      "177:\tlearn: 0.2022708\ttotal: 2.73s\tremaining: 3.4s\n",
      "178:\tlearn: 0.2018716\ttotal: 2.74s\tremaining: 3.38s\n",
      "179:\tlearn: 0.2012926\ttotal: 2.75s\tremaining: 3.37s\n",
      "180:\tlearn: 0.2001498\ttotal: 2.77s\tremaining: 3.35s\n",
      "181:\tlearn: 0.1997724\ttotal: 2.78s\tremaining: 3.33s\n",
      "182:\tlearn: 0.1992852\ttotal: 2.8s\tremaining: 3.32s\n",
      "183:\tlearn: 0.1989709\ttotal: 2.81s\tremaining: 3.3s\n",
      "184:\tlearn: 0.1987268\ttotal: 2.83s\tremaining: 3.29s\n",
      "185:\tlearn: 0.1983392\ttotal: 2.85s\tremaining: 3.27s\n",
      "186:\tlearn: 0.1980714\ttotal: 2.86s\tremaining: 3.26s\n",
      "187:\tlearn: 0.1977649\ttotal: 2.88s\tremaining: 3.24s\n",
      "188:\tlearn: 0.1972624\ttotal: 2.89s\tremaining: 3.23s\n",
      "189:\tlearn: 0.1968436\ttotal: 2.91s\tremaining: 3.21s\n",
      "190:\tlearn: 0.1963918\ttotal: 2.92s\tremaining: 3.2s\n",
      "191:\tlearn: 0.1960422\ttotal: 2.94s\tremaining: 3.18s\n",
      "192:\tlearn: 0.1957700\ttotal: 2.95s\tremaining: 3.17s\n",
      "193:\tlearn: 0.1953839\ttotal: 2.97s\tremaining: 3.15s\n",
      "194:\tlearn: 0.1944083\ttotal: 2.98s\tremaining: 3.13s\n",
      "195:\tlearn: 0.1939338\ttotal: 3s\tremaining: 3.12s\n",
      "196:\tlearn: 0.1935300\ttotal: 3.01s\tremaining: 3.1s\n",
      "197:\tlearn: 0.1931907\ttotal: 3.03s\tremaining: 3.09s\n",
      "198:\tlearn: 0.1924675\ttotal: 3.04s\tremaining: 3.07s\n",
      "199:\tlearn: 0.1920885\ttotal: 3.06s\tremaining: 3.06s\n",
      "200:\tlearn: 0.1916905\ttotal: 3.07s\tremaining: 3.04s\n",
      "201:\tlearn: 0.1909503\ttotal: 3.09s\tremaining: 3.03s\n",
      "202:\tlearn: 0.1906272\ttotal: 3.1s\tremaining: 3.01s\n",
      "203:\tlearn: 0.1903656\ttotal: 3.12s\tremaining: 2.99s\n",
      "204:\tlearn: 0.1897123\ttotal: 3.13s\tremaining: 2.98s\n",
      "205:\tlearn: 0.1892329\ttotal: 3.15s\tremaining: 2.96s\n",
      "206:\tlearn: 0.1888831\ttotal: 3.16s\tremaining: 2.95s\n",
      "207:\tlearn: 0.1886207\ttotal: 3.17s\tremaining: 2.93s\n",
      "208:\tlearn: 0.1883065\ttotal: 3.19s\tremaining: 2.92s\n",
      "209:\tlearn: 0.1878927\ttotal: 3.21s\tremaining: 2.9s\n",
      "210:\tlearn: 0.1870922\ttotal: 3.22s\tremaining: 2.88s\n",
      "211:\tlearn: 0.1868391\ttotal: 3.24s\tremaining: 2.87s\n",
      "212:\tlearn: 0.1865993\ttotal: 3.25s\tremaining: 2.85s\n",
      "213:\tlearn: 0.1861976\ttotal: 3.27s\tremaining: 2.84s\n",
      "214:\tlearn: 0.1857928\ttotal: 3.28s\tremaining: 2.83s\n",
      "215:\tlearn: 0.1852029\ttotal: 3.3s\tremaining: 2.81s\n",
      "216:\tlearn: 0.1848634\ttotal: 3.31s\tremaining: 2.79s\n",
      "217:\tlearn: 0.1845000\ttotal: 3.33s\tremaining: 2.78s\n",
      "218:\tlearn: 0.1843094\ttotal: 3.34s\tremaining: 2.76s\n",
      "219:\tlearn: 0.1839696\ttotal: 3.36s\tremaining: 2.75s\n",
      "220:\tlearn: 0.1825923\ttotal: 3.38s\tremaining: 2.73s\n",
      "221:\tlearn: 0.1820891\ttotal: 3.39s\tremaining: 2.72s\n",
      "222:\tlearn: 0.1818754\ttotal: 3.41s\tremaining: 2.71s\n",
      "223:\tlearn: 0.1814878\ttotal: 3.42s\tremaining: 2.69s\n",
      "224:\tlearn: 0.1808929\ttotal: 3.44s\tremaining: 2.68s\n",
      "225:\tlearn: 0.1806574\ttotal: 3.46s\tremaining: 2.66s\n",
      "226:\tlearn: 0.1803730\ttotal: 3.47s\tremaining: 2.65s\n",
      "227:\tlearn: 0.1800663\ttotal: 3.48s\tremaining: 2.63s\n",
      "228:\tlearn: 0.1796098\ttotal: 3.5s\tremaining: 2.61s\n",
      "229:\tlearn: 0.1791177\ttotal: 3.51s\tremaining: 2.6s\n",
      "230:\tlearn: 0.1787552\ttotal: 3.53s\tremaining: 2.58s\n",
      "231:\tlearn: 0.1783214\ttotal: 3.54s\tremaining: 2.56s\n",
      "232:\tlearn: 0.1779433\ttotal: 3.56s\tremaining: 2.55s\n",
      "233:\tlearn: 0.1777031\ttotal: 3.57s\tremaining: 2.53s\n",
      "234:\tlearn: 0.1772673\ttotal: 3.59s\tremaining: 2.52s\n",
      "235:\tlearn: 0.1769392\ttotal: 3.6s\tremaining: 2.5s\n",
      "236:\tlearn: 0.1761519\ttotal: 3.62s\tremaining: 2.49s\n",
      "237:\tlearn: 0.1751096\ttotal: 3.63s\tremaining: 2.47s\n",
      "238:\tlearn: 0.1747005\ttotal: 3.65s\tremaining: 2.46s\n",
      "239:\tlearn: 0.1744247\ttotal: 3.66s\tremaining: 2.44s\n",
      "240:\tlearn: 0.1735117\ttotal: 3.67s\tremaining: 2.42s\n",
      "241:\tlearn: 0.1731514\ttotal: 3.69s\tremaining: 2.41s\n",
      "242:\tlearn: 0.1729493\ttotal: 3.71s\tremaining: 2.39s\n",
      "243:\tlearn: 0.1726386\ttotal: 3.72s\tremaining: 2.38s\n",
      "244:\tlearn: 0.1723687\ttotal: 3.73s\tremaining: 2.36s\n",
      "245:\tlearn: 0.1716437\ttotal: 3.75s\tremaining: 2.35s\n",
      "246:\tlearn: 0.1712218\ttotal: 3.77s\tremaining: 2.33s\n",
      "247:\tlearn: 0.1707791\ttotal: 3.78s\tremaining: 2.32s\n",
      "248:\tlearn: 0.1704167\ttotal: 3.79s\tremaining: 2.3s\n",
      "249:\tlearn: 0.1700213\ttotal: 3.81s\tremaining: 2.29s\n",
      "250:\tlearn: 0.1697664\ttotal: 3.83s\tremaining: 2.27s\n",
      "251:\tlearn: 0.1695463\ttotal: 3.84s\tremaining: 2.26s\n",
      "252:\tlearn: 0.1691806\ttotal: 3.86s\tremaining: 2.24s\n",
      "253:\tlearn: 0.1687045\ttotal: 3.88s\tremaining: 2.23s\n",
      "254:\tlearn: 0.1685015\ttotal: 3.89s\tremaining: 2.21s\n",
      "255:\tlearn: 0.1681998\ttotal: 3.91s\tremaining: 2.2s\n",
      "256:\tlearn: 0.1678410\ttotal: 3.92s\tremaining: 2.18s\n",
      "257:\tlearn: 0.1675778\ttotal: 3.94s\tremaining: 2.17s\n",
      "258:\tlearn: 0.1667106\ttotal: 3.95s\tremaining: 2.15s\n",
      "259:\tlearn: 0.1664402\ttotal: 3.97s\tremaining: 2.14s\n",
      "260:\tlearn: 0.1655978\ttotal: 3.98s\tremaining: 2.12s\n",
      "261:\tlearn: 0.1653732\ttotal: 3.99s\tremaining: 2.1s\n",
      "262:\tlearn: 0.1647201\ttotal: 4.01s\tremaining: 2.09s\n",
      "263:\tlearn: 0.1641902\ttotal: 4.03s\tremaining: 2.07s\n",
      "264:\tlearn: 0.1639084\ttotal: 4.04s\tremaining: 2.06s\n",
      "265:\tlearn: 0.1630543\ttotal: 4.06s\tremaining: 2.04s\n",
      "266:\tlearn: 0.1628393\ttotal: 4.07s\tremaining: 2.03s\n",
      "267:\tlearn: 0.1625937\ttotal: 4.08s\tremaining: 2.01s\n",
      "268:\tlearn: 0.1623738\ttotal: 4.1s\tremaining: 2s\n",
      "269:\tlearn: 0.1615052\ttotal: 4.12s\tremaining: 1.98s\n",
      "270:\tlearn: 0.1612782\ttotal: 4.13s\tremaining: 1.97s\n",
      "271:\tlearn: 0.1609891\ttotal: 4.15s\tremaining: 1.95s\n",
      "272:\tlearn: 0.1607874\ttotal: 4.16s\tremaining: 1.94s\n",
      "273:\tlearn: 0.1603773\ttotal: 4.18s\tremaining: 1.92s\n",
      "274:\tlearn: 0.1601056\ttotal: 4.19s\tremaining: 1.9s\n",
      "275:\tlearn: 0.1596073\ttotal: 4.21s\tremaining: 1.89s\n",
      "276:\tlearn: 0.1593554\ttotal: 4.22s\tremaining: 1.87s\n",
      "277:\tlearn: 0.1589730\ttotal: 4.24s\tremaining: 1.86s\n",
      "278:\tlearn: 0.1588164\ttotal: 4.25s\tremaining: 1.84s\n",
      "279:\tlearn: 0.1584071\ttotal: 4.27s\tremaining: 1.83s\n",
      "280:\tlearn: 0.1579383\ttotal: 4.28s\tremaining: 1.81s\n",
      "281:\tlearn: 0.1576532\ttotal: 4.3s\tremaining: 1.8s\n",
      "282:\tlearn: 0.1572473\ttotal: 4.31s\tremaining: 1.78s\n",
      "283:\tlearn: 0.1568383\ttotal: 4.33s\tremaining: 1.77s\n",
      "284:\tlearn: 0.1562218\ttotal: 4.34s\tremaining: 1.75s\n",
      "285:\tlearn: 0.1560376\ttotal: 4.36s\tremaining: 1.74s\n",
      "286:\tlearn: 0.1558497\ttotal: 4.37s\tremaining: 1.72s\n",
      "287:\tlearn: 0.1556604\ttotal: 4.39s\tremaining: 1.71s\n",
      "288:\tlearn: 0.1554384\ttotal: 4.4s\tremaining: 1.69s\n",
      "289:\tlearn: 0.1551196\ttotal: 4.42s\tremaining: 1.67s\n",
      "290:\tlearn: 0.1545615\ttotal: 4.43s\tremaining: 1.66s\n",
      "291:\tlearn: 0.1543565\ttotal: 4.45s\tremaining: 1.65s\n",
      "292:\tlearn: 0.1541258\ttotal: 4.46s\tremaining: 1.63s\n",
      "293:\tlearn: 0.1537186\ttotal: 4.48s\tremaining: 1.61s\n",
      "294:\tlearn: 0.1533895\ttotal: 4.49s\tremaining: 1.6s\n",
      "295:\tlearn: 0.1531861\ttotal: 4.51s\tremaining: 1.58s\n",
      "296:\tlearn: 0.1526846\ttotal: 4.53s\tremaining: 1.57s\n",
      "297:\tlearn: 0.1525217\ttotal: 4.54s\tremaining: 1.55s\n",
      "298:\tlearn: 0.1520874\ttotal: 4.55s\tremaining: 1.54s\n",
      "299:\tlearn: 0.1516867\ttotal: 4.57s\tremaining: 1.52s\n",
      "300:\tlearn: 0.1513625\ttotal: 4.59s\tremaining: 1.51s\n",
      "301:\tlearn: 0.1510803\ttotal: 4.6s\tremaining: 1.49s\n",
      "302:\tlearn: 0.1501503\ttotal: 4.62s\tremaining: 1.48s\n",
      "303:\tlearn: 0.1499725\ttotal: 4.64s\tremaining: 1.46s\n",
      "304:\tlearn: 0.1496784\ttotal: 4.65s\tremaining: 1.45s\n",
      "305:\tlearn: 0.1492322\ttotal: 4.67s\tremaining: 1.43s\n",
      "306:\tlearn: 0.1488931\ttotal: 4.68s\tremaining: 1.42s\n",
      "307:\tlearn: 0.1486387\ttotal: 4.7s\tremaining: 1.4s\n",
      "308:\tlearn: 0.1481080\ttotal: 4.71s\tremaining: 1.39s\n",
      "309:\tlearn: 0.1468940\ttotal: 4.73s\tremaining: 1.37s\n",
      "310:\tlearn: 0.1466818\ttotal: 4.74s\tremaining: 1.36s\n",
      "311:\tlearn: 0.1461787\ttotal: 4.75s\tremaining: 1.34s\n",
      "312:\tlearn: 0.1455519\ttotal: 4.77s\tremaining: 1.32s\n",
      "313:\tlearn: 0.1452988\ttotal: 4.78s\tremaining: 1.31s\n",
      "314:\tlearn: 0.1450183\ttotal: 4.8s\tremaining: 1.29s\n",
      "315:\tlearn: 0.1447292\ttotal: 4.81s\tremaining: 1.28s\n",
      "316:\tlearn: 0.1445171\ttotal: 4.83s\tremaining: 1.26s\n",
      "317:\tlearn: 0.1440980\ttotal: 4.84s\tremaining: 1.25s\n",
      "318:\tlearn: 0.1439535\ttotal: 4.86s\tremaining: 1.23s\n",
      "319:\tlearn: 0.1433655\ttotal: 4.88s\tremaining: 1.22s\n",
      "320:\tlearn: 0.1431897\ttotal: 4.89s\tremaining: 1.2s\n",
      "321:\tlearn: 0.1429045\ttotal: 4.91s\tremaining: 1.19s\n",
      "322:\tlearn: 0.1427321\ttotal: 4.92s\tremaining: 1.17s\n",
      "323:\tlearn: 0.1425186\ttotal: 4.94s\tremaining: 1.16s\n",
      "324:\tlearn: 0.1423463\ttotal: 4.95s\tremaining: 1.14s\n",
      "325:\tlearn: 0.1421525\ttotal: 4.97s\tremaining: 1.13s\n",
      "326:\tlearn: 0.1420248\ttotal: 4.98s\tremaining: 1.11s\n",
      "327:\tlearn: 0.1414830\ttotal: 5s\tremaining: 1.1s\n",
      "328:\tlearn: 0.1413301\ttotal: 5.02s\tremaining: 1.08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329:\tlearn: 0.1410034\ttotal: 5.03s\tremaining: 1.07s\n",
      "330:\tlearn: 0.1407420\ttotal: 5.04s\tremaining: 1.05s\n",
      "331:\tlearn: 0.1405444\ttotal: 5.06s\tremaining: 1.04s\n",
      "332:\tlearn: 0.1403682\ttotal: 5.07s\tremaining: 1.02s\n",
      "333:\tlearn: 0.1400961\ttotal: 5.09s\tremaining: 1s\n",
      "334:\tlearn: 0.1397194\ttotal: 5.1s\tremaining: 990ms\n",
      "335:\tlearn: 0.1395319\ttotal: 5.12s\tremaining: 975ms\n",
      "336:\tlearn: 0.1388751\ttotal: 5.13s\tremaining: 959ms\n",
      "337:\tlearn: 0.1386390\ttotal: 5.15s\tremaining: 944ms\n",
      "338:\tlearn: 0.1384799\ttotal: 5.16s\tremaining: 929ms\n",
      "339:\tlearn: 0.1381193\ttotal: 5.17s\tremaining: 913ms\n",
      "340:\tlearn: 0.1379233\ttotal: 5.19s\tremaining: 898ms\n",
      "341:\tlearn: 0.1376609\ttotal: 5.2s\tremaining: 883ms\n",
      "342:\tlearn: 0.1374825\ttotal: 5.22s\tremaining: 867ms\n",
      "343:\tlearn: 0.1370295\ttotal: 5.23s\tremaining: 852ms\n",
      "344:\tlearn: 0.1367870\ttotal: 5.25s\tremaining: 837ms\n",
      "345:\tlearn: 0.1364118\ttotal: 5.26s\tremaining: 822ms\n",
      "346:\tlearn: 0.1362739\ttotal: 5.28s\tremaining: 806ms\n",
      "347:\tlearn: 0.1361275\ttotal: 5.29s\tremaining: 791ms\n",
      "348:\tlearn: 0.1359572\ttotal: 5.31s\tremaining: 776ms\n",
      "349:\tlearn: 0.1357915\ttotal: 5.32s\tremaining: 760ms\n",
      "350:\tlearn: 0.1354838\ttotal: 5.34s\tremaining: 745ms\n",
      "351:\tlearn: 0.1353464\ttotal: 5.35s\tremaining: 730ms\n",
      "352:\tlearn: 0.1350367\ttotal: 5.37s\tremaining: 714ms\n",
      "353:\tlearn: 0.1347942\ttotal: 5.38s\tremaining: 699ms\n",
      "354:\tlearn: 0.1345866\ttotal: 5.39s\tremaining: 684ms\n",
      "355:\tlearn: 0.1343493\ttotal: 5.41s\tremaining: 669ms\n",
      "356:\tlearn: 0.1340704\ttotal: 5.42s\tremaining: 653ms\n",
      "357:\tlearn: 0.1339115\ttotal: 5.44s\tremaining: 638ms\n",
      "358:\tlearn: 0.1336679\ttotal: 5.46s\tremaining: 623ms\n",
      "359:\tlearn: 0.1333432\ttotal: 5.47s\tremaining: 608ms\n",
      "360:\tlearn: 0.1326803\ttotal: 5.48s\tremaining: 592ms\n",
      "361:\tlearn: 0.1324766\ttotal: 5.5s\tremaining: 577ms\n",
      "362:\tlearn: 0.1322963\ttotal: 5.51s\tremaining: 562ms\n",
      "363:\tlearn: 0.1319294\ttotal: 5.53s\tremaining: 546ms\n",
      "364:\tlearn: 0.1317905\ttotal: 5.54s\tremaining: 531ms\n",
      "365:\tlearn: 0.1315386\ttotal: 5.55s\tremaining: 516ms\n",
      "366:\tlearn: 0.1313985\ttotal: 5.57s\tremaining: 501ms\n",
      "367:\tlearn: 0.1312877\ttotal: 5.58s\tremaining: 485ms\n",
      "368:\tlearn: 0.1311584\ttotal: 5.6s\tremaining: 470ms\n",
      "369:\tlearn: 0.1306843\ttotal: 5.61s\tremaining: 455ms\n",
      "370:\tlearn: 0.1303531\ttotal: 5.63s\tremaining: 440ms\n",
      "371:\tlearn: 0.1301643\ttotal: 5.64s\tremaining: 425ms\n",
      "372:\tlearn: 0.1298751\ttotal: 5.66s\tremaining: 409ms\n",
      "373:\tlearn: 0.1295911\ttotal: 5.67s\tremaining: 394ms\n",
      "374:\tlearn: 0.1294642\ttotal: 5.68s\tremaining: 379ms\n",
      "375:\tlearn: 0.1293410\ttotal: 5.7s\tremaining: 364ms\n",
      "376:\tlearn: 0.1291997\ttotal: 5.71s\tremaining: 349ms\n",
      "377:\tlearn: 0.1288927\ttotal: 5.73s\tremaining: 333ms\n",
      "378:\tlearn: 0.1287427\ttotal: 5.74s\tremaining: 318ms\n",
      "379:\tlearn: 0.1282825\ttotal: 5.76s\tremaining: 303ms\n",
      "380:\tlearn: 0.1280919\ttotal: 5.77s\tremaining: 288ms\n",
      "381:\tlearn: 0.1279408\ttotal: 5.79s\tremaining: 273ms\n",
      "382:\tlearn: 0.1277393\ttotal: 5.8s\tremaining: 257ms\n",
      "383:\tlearn: 0.1273517\ttotal: 5.82s\tremaining: 242ms\n",
      "384:\tlearn: 0.1272245\ttotal: 5.83s\tremaining: 227ms\n",
      "385:\tlearn: 0.1265508\ttotal: 5.85s\tremaining: 212ms\n",
      "386:\tlearn: 0.1264196\ttotal: 5.86s\tremaining: 197ms\n",
      "387:\tlearn: 0.1260400\ttotal: 5.87s\tremaining: 182ms\n",
      "388:\tlearn: 0.1259295\ttotal: 5.89s\tremaining: 167ms\n",
      "389:\tlearn: 0.1254953\ttotal: 5.9s\tremaining: 151ms\n",
      "390:\tlearn: 0.1253146\ttotal: 5.92s\tremaining: 136ms\n",
      "391:\tlearn: 0.1252038\ttotal: 5.93s\tremaining: 121ms\n",
      "392:\tlearn: 0.1248803\ttotal: 5.95s\tremaining: 106ms\n",
      "393:\tlearn: 0.1245355\ttotal: 5.96s\tremaining: 90.8ms\n",
      "394:\tlearn: 0.1241144\ttotal: 5.98s\tremaining: 75.7ms\n",
      "395:\tlearn: 0.1235463\ttotal: 6s\tremaining: 60.6ms\n",
      "396:\tlearn: 0.1234111\ttotal: 6.01s\tremaining: 45.4ms\n",
      "397:\tlearn: 0.1229520\ttotal: 6.03s\tremaining: 30.3ms\n",
      "398:\tlearn: 0.1227529\ttotal: 6.04s\tremaining: 15.1ms\n",
      "399:\tlearn: 0.1225700\ttotal: 6.06s\tremaining: 0us\n",
      "\n",
      "CatBoost Results:\n",
      "Accuracy: 0.8680555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.69      0.65        29\n",
      "     neutral       0.57      0.31      0.40        39\n",
      "    positive       0.93      0.99      0.96       220\n",
      "\n",
      "    accuracy                           0.87       288\n",
      "   macro avg       0.70      0.66      0.67       288\n",
      "weighted avg       0.85      0.87      0.85       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# CatBoost\n",
    "catboost_model = CatBoostClassifier(iterations=400, depth=5, learning_rate=0.1, loss_function='MultiClass')\n",
    "catboost_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "catboost_predictions = catboost_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the CatBoost model\n",
    "print(\"\\nCatBoost Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, catboost_predictions))\n",
    "print(classification_report(y_test, catboost_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2851132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy: 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.76      0.70        29\n",
      "     neutral       0.60      0.31      0.41        39\n",
      "    positive       0.93      0.99      0.96       220\n",
      "\n",
      "    accuracy                           0.88       288\n",
      "   macro avg       0.73      0.69      0.69       288\n",
      "weighted avg       0.86      0.88      0.86       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_predictions = rf_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(classification_report(y_test, rf_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "275f79f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3d06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "# from sklearn.preprocessing import LabelEncoder # to encode target class,+ve ,-ve  and neutral\n",
    "\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# # Load the pre-trained BERT model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # Assuming 3 classes for sentiment\n",
    "\n",
    "# # Tokenize and encode the training and testing data\n",
    "# X_train_tokens = tokenizer.batch_encode_plus(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "# X_test_tokens = tokenizer.batch_encode_plus(X_test.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# # Create TensorDatasets\n",
    "# train_dataset = TensorDataset(X_train_tokens['input_ids'], X_train_tokens['attention_mask'], torch.tensor(y_train_encoded,dtype=torch.long))\n",
    "# test_dataset = TensorDataset(X_test_tokens['input_ids'], X_test_tokens['attention_mask'], torch.tensor(y_test_encoded,dtype=torch.long))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98a778c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create DataLoader\n",
    "# batch_size = 32\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "# test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "# # Set up GPU/CPU device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "# # Set up optimizer and training parameters\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "# epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27fd6b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mepochs\u001b[49m):\n\u001b[0;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        val_loss += outputs.loss.item()\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        val_accuracy += torch.sum(preds == labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_dataloader)\n",
    "    val_accuracy = val_accuracy / len(X_test)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print(f'Training Loss: {avg_train_loss}')\n",
    "    print(f'Validation Loss: {avg_val_loss}')\n",
    "    print(f'Validation Accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f20ad5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    input_ids, attention_mask, _ = batch\n",
    "    input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"BERT Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, predictions))\n",
    "print(classification_report(y_test_encoded, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1a1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dash dash-bootstrap-components pandas plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec9fb56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x282f5cee3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "# Assume you have a DataFrame called 'sentiment_data' with columns: 'Feedback', 'Sentiment', 'Date'\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "# Sample Data\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "# Generate a Stacked Bar Chart for Department Name by Sentiment\n",
    "stacked_bar_chart = px.bar(df, x='Department Name', color='Sentiment', title='Sentiment Distribution by Department', barmode='stack')\n",
    "# Generate a Heatmap for correlation between numeric columns\n",
    "correlation_heatmap = px.imshow(df.corr(), x=df.corr().columns, y=df.corr().columns, title='Correlation Heatmap')\n",
    "\n",
    "# Count plot of Division Name and Department Name\n",
    "count_plot = px.histogram(df, x='Division Name', color='Department Name', title='Count Plot of Division Name and Department Name')\n",
    "\n",
    "# Group by Rating and Department Name, and then count the occurrences\n",
    "rating_department_count = df.groupby(['Rating', 'Department Name']).size().reset_index(name='Count')\n",
    "\n",
    "# Stacked bar chart of Department count for each Rating\n",
    "rating_department_count_chart = px.bar(rating_department_count, x='Rating', y='Count', color='Department Name',\n",
    "                                       title='Department Count for Each Rating', barmode='stack')\n",
    "\n",
    "recommended_sentiment_count = df.groupby(['Sentiment', 'Recommended IND']).size().reset_index(name='Count')\n",
    "timent = px.bar(df, x='Sentiment', color='Recommended IND', title='Count of Recommended Products by Sentiment', barmode='group')\n",
    "# Group by Sentiment and Recommended IND, and then count the occurrences\n",
    "recommended_sentiment_count = df.groupby(['Sentiment', 'Recommended IND']).size().reset_index(name='Count')\n",
    "\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "#Define the layout of your dashboard\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Customer Feedback Dashboard\"),\n",
    "    \n",
    "    dcc.Graph(\n",
    "        id='sentiment-pie-chart',\n",
    "        figure=px.pie(df, values='Rating', names='Sentiment', title='Sentiment Distribution')\n",
    "    ),\n",
    "    \n",
    "    # Count plot of Division Name and Department Name\n",
    "    dcc.Graph(\n",
    "        id='count-plot',\n",
    "        figure=count_plot\n",
    "    ),\n",
    "    \n",
    "     dcc.Graph(\n",
    "        id='age-histogram',\n",
    "        figure=px.histogram(df, x='Age', nbins=10, title='Histogram of Age')\n",
    "    ),\n",
    "     \n",
    "     \n",
    "    # Stacked Bar Chart of Department Name by Sentiment\n",
    "    dcc.Graph(\n",
    "        id='sentiment-stacked-bar-chart',\n",
    "        figure=stacked_bar_chart\n",
    "    ),\n",
    "    # Heatmap of Correlation\n",
    "    dcc.Graph(\n",
    "        id='correlation-heatmap',\n",
    "        figure=correlation_heatmap\n",
    "    ),\n",
    "     # Stacked bar chart of Department count for each Rating\n",
    "    dcc.Graph(\n",
    "        id='rating-department-count-chart',\n",
    "        figure=rating_department_count_chart\n",
    "    )\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True,mode=\"inline\")\n",
    "# Expected one of ['Clothing ID', 'Age', 'Title', 'Review Text', 'Rating', 'Recommended IND', \n",
    "# 'Positive Feedback Count', 'Division Name', 'Department Name', 'Class Name', 'Sentiment'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6933aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fdf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca424dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51733113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f88cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30ae04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dac304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362b580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635e503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179f084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e8506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0ea87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5fc17f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
